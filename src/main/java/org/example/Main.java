package org.example;

import org.apache.spark.sql.*;
import java.text.Normalizer;
import java.util.Arrays;

public class Main {
    public static void main(String[] args) {
        // Initialisation de Spark
        SparkSession spark = SparkSession.builder()
                .appName("OpenFoodFactsIntegration")
                .config("spark.master", "local")
                .getOrCreate();

        // Chargement du fichier CSV
        Dataset<Row> df = spark.read()
                .option("header", "true")
                .option("inferSchema", "true")
                .csv("resources/en.openfoodfacts.org.products.csv");

        // Affichage des colonnes brutes
        System.out.println("Colonnes brutes du DataFrame : " + Arrays.toString(df.columns()));
        df.printSchema();

        // Nettoyage des noms de colonnes (suppression des espaces et caract√®res sp√©ciaux)
        String[] cleanedColumnNames = Arrays.stream(df.columns())
                .map(c -> Normalizer.normalize(c.trim(), Normalizer.Form.NFKC)) // Normalisation Unicode
                .map(c -> c.replaceAll("[^a-zA-Z0-9_]", "")) // Suppression des caract√®res sp√©ciaux
                .toArray(String[]::new);
        df = df.toDF(cleanedColumnNames);

        // Affichage des colonnes apr√®s nettoyage
        System.out.println("Colonnes apr√®s nettoyage : ");
        for (String col : df.columns()) {
            System.out.println("'" + col + "'");
        }

        // V√©rification du vrai nom de "product_name"
        for (String col : df.columns()) {
            if (col.toLowerCase().contains("product")) {
                System.out.println("üîç Possible nom de 'product_name' trouv√© : '" + col + "'");
            }
        }

        // V√©rification de la pr√©sence de "product_name"
        if (!Arrays.asList(df.columns()).contains("product_name")) {
            System.err.println("‚ö†Ô∏è Erreur : 'product_name' n'est pas trouv√©e dans le DataFrame !");
            spark.stop();
            return;
        }

        // Nettoyage
        df = DataCleaner.cleanData(df);

        // Transformation
        df = DataTransformer.transformData(df);

        // Export des donn√©es nettoy√©es
        DataExporter.exportData(df);

        // Agr√©gation et export des r√©sultats
        Dataset<Row> topBrands = DataAggregator.getTopBrands(df);
        DataExporter.exportAggregations(topBrands, "top_brands.csv");

        Dataset<Row> avgSugarEnergy = DataAggregator.getAverageSugarEnergyByCountry(df);
        DataExporter.exportAggregations(avgSugarEnergy, "avg_sugar_energy_by_country.csv");

        Dataset<Row> productLabels = DataAggregator.getProductDistributionByLabels(df);
        DataExporter.exportAggregations(productLabels, "product_distribution_by_labels.csv");

        // Fermeture de Spark
        spark.stop();
    }
}
